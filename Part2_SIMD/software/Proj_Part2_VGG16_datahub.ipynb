{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add parent directory to path to import models if needed, though we will define custom classes here\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from models.quant_layer import weight_quantize_fn, act_quantization\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(f'Using GPU: {use_gpu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "Here we define the custom VGG model with:\n",
    "1. **2-bit Activation** and **4-bit Weight** quantization.\n",
    "2. A specific layer (around 27th) squeezed to **16 channels** with **Batch Normalization removed**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantConv2d_Custom(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, a_bit=2, w_bit=4):\n",
    "        super(QuantConv2d_Custom, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "        self.layer_type = 'QuantConv2d_Custom'\n",
    "        self.w_bit = w_bit \n",
    "        self.a_bit = a_bit\n",
    "        self.weight_quant = weight_quantize_fn(w_bit=w_bit)\n",
    "        self.act_alq = act_quantization(a_bit)\n",
    "        self.act_alpha = torch.nn.Parameter(torch.tensor(8.0))\n",
    "        self.weight_q  = torch.nn.Parameter(torch.zeros([out_channels, in_channels, kernel_size, kernel_size]))\n",
    "        self.is_quantized = False # Flag to track if quantization has happened\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weight_q = self.weight_quant(self.weight)       \n",
    "        self.weight_q = torch.nn.Parameter(weight_q) # Store quantized weight for verification\n",
    "        self.is_quantized = True\n",
    "        x = self.act_alq(x, self.act_alpha)\n",
    "        return F.conv2d(x, weight_q, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "    \n",
    "    def show_params(self):\n",
    "        wgt_alpha = round(self.weight_quant.wgt_alpha.data.item(), 3)\n",
    "        act_alpha = round(self.act_alpha.data.item(), 3)\n",
    "        print('clipping threshold weight alpha: {:2f}, activation alpha: {:2f}'.format(wgt_alpha, act_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified configuration for VGG16\n",
    "# Original: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "# We modify the block after the 3rd 'M' (MaxPool). Input to this block is 256.\n",
    "# Original Block: 512, 512, 512\n",
    "# Modified Block: 16, '16_no_bn', 512\n",
    "# 1. Conv(256 -> 16) -> BN -> ReLU\n",
    "# 2. Conv(16 -> 16) -> ReLU (No BN) [Target Layer]\n",
    "# 3. Conv(16 -> 512) -> BN -> ReLU\n",
    "\n",
    "cfg_custom = {\n",
    "    'VGG16_HW6': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 16, '16_no_bn', 512, 'M', 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG_quant_Custom(nn.Module):\n",
    "    def __init__(self, vgg_name='VGG16_HW6', a_bit=2, w_bit=4):\n",
    "        super(VGG_quant_Custom, self).__init__()\n",
    "        self.a_bit = a_bit\n",
    "        self.w_bit = w_bit\n",
    "        self.features = self._make_layers(cfg_custom[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            elif x == 'F': \n",
    "                # 1st layer usually high precision or standard, keeping standard Conv2d\n",
    "                layers += [nn.Conv2d(in_channels, 64, kernel_size=3, padding=1, bias=False),\n",
    "                           nn.BatchNorm2d(64),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = 64\n",
    "            elif isinstance(x, str) and '_no_bn' in x:\n",
    "                # Special case: No BN layer\n",
    "                out_ch = int(x.replace('_no_bn', ''))\n",
    "                layers += [QuantConv2d_Custom(in_channels, out_ch, kernel_size=3, padding=1, a_bit=self.a_bit, w_bit=self.w_bit),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = out_ch\n",
    "            else:\n",
    "                # Standard Quantized Layer\n",
    "                layers += [QuantConv2d_Custom(in_channels, x, kernel_size=3, padding=1, a_bit=self.a_bit, w_bit=self.w_bit),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def show_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, QuantConv2d_Custom):\n",
    "                m.show_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, criterion, optimizer, epoch, print_freq=100):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "def validate(val_loader, model, criterion, print_freq=100):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "=> Loading Data...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./result/VGG16_HW6_2bit_act_4bit_wgt\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "lr = 0.1\n",
    "weight_decay = 1e-4\n",
    "epochs = 250\n",
    "print_freq = 100\n",
    "model_name = \"VGG16_HW6_2bit_act_4bit_wgt\"\n",
    "\n",
    "print('=> Building model...')\n",
    "model = VGG_quant_Custom(vgg_name='VGG16_HW6', a_bit=2, w_bit=4)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "print('=> Loading Data...')\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "# Ensure data path is correct. If running in software/hw/, data might be in ../data or ./data\n",
    "# Adjust root as necessary\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='../data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Results Directory\n",
    "if not os.path.exists('../result'):\n",
    "    os.makedirs('../result')\n",
    "fdir = './result/'+str(model_name)\n",
    "print(fdir)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_prec = 0\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print(f\"Epoch {epoch} started...\")\n",
    "    train(trainloader, model, criterion, optimizer, epoch, print_freq)\n",
    "    # scheduler.step()\n",
    "    \n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion, print_freq)\n",
    "\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec, best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8903/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test set accuracy\n",
    "PATH = \"./result/VGG16_HW6_2bit_act_4bit_wgt/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSUM Recovery and Verification\n",
    "\n",
    "Here we verify that the `psum_recovered` matches the pre-hooked input for the next layer.\n",
    "1. We hook the input of the **Target Layer** (16->16).\n",
    "2. We hook the input of the **Next Layer** (16->512). This serves as our reference output (post-ReLU).\n",
    "3. We verify that `Conv(quantized_input) -> ReLU` matches the reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint ./result/VGG16_HW6_2bit_act_4bit_wgt/model_best.pth.tar\n",
      "Target Layer: QuantConv2d_Custom(\n",
      "  16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "Next Layer: QuantConv2d_Custom(\n",
      "  16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "Input shape: torch.Size([128, 16, 4, 4])\n",
      "Reference Output shape: torch.Size([128, 16, 4, 4])\n",
      "Mean Difference: 2.2487314765839983e-07\n",
      "SUCCESS: PSUM Recovery Verified!\n"
     ]
    }
   ],
   "source": [
    "# Load Best Model (If available)\n",
    "model_path = os.path.join(fdir, 'model_best.pth.tar')\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"=> Loading checkpoint {model_path}\")\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    print(\"No checkpoint found. Using random weights for demonstration.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Indices based on cfg_custom['VGG16_HW6']\n",
    "# [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 16, '16_no_bn', 512, ...]\n",
    "# Blocks before: \n",
    "# 64 block: 2 layers (idx 0-6 with M)\n",
    "# 128 block: 2 layers (idx 7-13 with M)\n",
    "# 256 block: 3 layers (idx 14-23 with M)\n",
    "# 512 block start:\n",
    "#   24: Conv(256->16)\n",
    "#   25: BN\n",
    "#   26: ReLU\n",
    "#   27: Conv(16->16) [Target, No BN]\n",
    "#   28: ReLU\n",
    "#   29: Conv(16->512)\n",
    "\n",
    "target_layer_idx = 27\n",
    "next_layer_idx = 29\n",
    "\n",
    "print(f\"Target Layer: {model.features[target_layer_idx]}\")\n",
    "print(f\"Next Layer: {model.features[next_layer_idx]}\")\n",
    "\n",
    "# Hook Setup\n",
    "class SaveInput:\n",
    "    def __init__(self):\n",
    "        self.inputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.inputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.inputs = []\n",
    "        \n",
    "save_input_target = SaveInput()\n",
    "save_input_next = SaveInput()\n",
    "\n",
    "hook_target = model.features[target_layer_idx].register_forward_pre_hook(save_input_target)\n",
    "hook_next = model.features[next_layer_idx].register_forward_pre_hook(save_input_next)\n",
    "\n",
    "# Run Inference\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.cuda() if use_gpu else images\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(images)\n",
    "    \n",
    "# Get Captured Inputs\n",
    "x_input = save_input_target.inputs[0][0] # Input to 16->16 layer\n",
    "x_ref_next = save_input_next.inputs[0][0] # Input to 16->512 layer (Reference Output of 16->16)\n",
    "\n",
    "print(f\"Input shape: {x_input.shape}\")\n",
    "print(f\"Reference Output shape: {x_ref_next.shape}\")\n",
    "\n",
    "# Check if quantization was actually performed\n",
    "# If the model is new and un-trained/un-forwarded, weight_q might be all zeros if initialized that way in __init__\n",
    "# But in our QuantConv2d_Custom, weight_q is a Parameter initialized to zeros, BUT it is updated in forward().\n",
    "# Since we just ran model(images), forward() was called, so weight_q should be populated with quantized values.\n",
    "\n",
    "target_layer = model.features[target_layer_idx]\n",
    "\n",
    "if not getattr(target_layer, 'is_quantized', False):\n",
    "    print(\"WARNING: Layer reports it has not been quantized! Check forward pass logic.\")\n",
    "\n",
    "# PSUM Recovery Calculation\n",
    "act_q = target_layer.act_alq(x_input, target_layer.act_alpha)\n",
    "act_bit = 4 \n",
    "act_alpha = target_layer.act_alpha\n",
    "act_delta = act_alpha/(2**act_bit-1) \n",
    "act_int = act_q/act_delta\n",
    "weight_q = target_layer.weight_q\n",
    "w_bit = 4\n",
    "w_alpha = target_layer.weight_quant.wgt_alpha   # alpha is defined in your model already. bring it out here\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)    # delta can be calculated by using alpha and w_bit\n",
    "weight_int = weight_q/w_delta\n",
    "output_int_sim = F.conv2d(act_int, weight_int, target_layer.bias, target_layer.stride, target_layer.padding, target_layer.dilation, target_layer.groups)\n",
    "output_recovered = F.relu(output_int_sim)*w_delta*act_delta \n",
    "\n",
    "diff = (output_recovered - x_ref_next).abs().mean()\n",
    "print(f\"Mean Difference: {diff.item()}\")\n",
    "\n",
    "if diff.item() < 1e-3:\n",
    "    print(\"SUCCESS: PSUM Recovery Verified!\")\n",
    "else:\n",
    "    print(\"WARNING: Difference is high. Check quantization or layer logic.\")\n",
    "\n",
    "hook_target.remove()\n",
    "hook_next.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Write to activation.txt, psum.txt, weight.txt, output.txt\n",
    "a_int = x_quantized[0,:,:,:]  # pick only one input out of batch\n",
    "o_int = output_int_sim[0,:,:,:]\n",
    "# a_int.size() = [8, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([8, 8, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([8, 8, 9])\n",
    "                      \n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "ic_tileg = range(int(len(icg)/array_size))\n",
    "oc_tileg = range(int(len(ocg)/array_size))\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
    "# a_pad.size() = [8, 32+2pad, 32+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "# a_pad.size() = [8, (32+2pad)*(32+2pad)]\n",
    "o_int = torch.reshape(o_int, (o_int.size(0), -1))\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tileg), array_size,    a_pad.size(1)).cuda() \n",
    "w_tile = torch.zeros(len(oc_tileg)*len(ic_tileg), array_size, array_size, len(kijg)).cuda() \n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    a_tile[ic_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    for oc_tile in oc_tileg:\n",
    "        w_tile[oc_tile*len(oc_tileg) + ic_tile,:,:,:] = w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, :]\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## psum nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ic_tile in ic_tileg:       # Tiling into array_sizeXarray_size array\n",
    "        for oc_tile in oc_tileg:   # Tiling into array_sizeXarray_size array        \n",
    "            for nij in p_nijg:       # time domain, sequentially given input\n",
    "                    m = nn.Linear(array_size, array_size, bias=False)\n",
    "                    #m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
    "                    m.weight = torch.nn.Parameter(w_tile[len(oc_tileg)*oc_tile+ic_tile,:,:,kij])\n",
    "                    psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,:,nij]).cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1)))\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:\n",
    "        for ic_tile in ic_tileg:    \n",
    "            for oc_tile in oc_tileg:   \n",
    "                out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] = out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] + \\\n",
    "                psum[ic_tile, oc_tile, :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 4th index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)\n",
    "\n",
    "out = F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = 0 \n",
    "nij = 0 \n",
    "X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 2\n",
    "file = open('activation_2b.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:02b}'.format(round(X[7-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = 0 \n",
    "for kij in range(9):\n",
    "    W = w_tile[tile_id,:,:,kij]  # w_tile[tile_num, array col num, array row num, kij]\n",
    "    \n",
    "    bit_precision = 4\n",
    "    filename = f\"{'weight'}_{kij}{'_v2.txt'}\"\n",
    "    file = open(filename, 'w') #write to file\n",
    "    file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "    file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    \n",
    "    for i in range(W.size(1)):  # col\n",
    "        for j in range(W.size(0)):  # row\n",
    "            val = round(W[7-j,i].item())\n",
    "            if val < 0:\n",
    "                val = val + 2**bit_precision\n",
    "            W_bin = '{0:04b}'.format(val)\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_tile_id = 0 \n",
    "oc_tile_id = 0 \n",
    "\n",
    "kij = 0\n",
    "nij = 0\n",
    "psum_tile = psum[ic_tile_id,oc_tile_id,:,nij:nij+64,:]  \n",
    "# psum[len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)]\n",
    "\n",
    "bit_precision = 16\n",
    "file = open('psum_v2.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for y in range(9): # kij\n",
    "    for i in range(psum_tile.size(1)): # time\n",
    "        for j in range(psum_tile.size(0)): # col\n",
    "            val = round(psum_tile[7-j,i,y].item())\n",
    "            if val < 0:\n",
    "                val = val + 2**bit_precision\n",
    "            psum_bin = '{0:016b}'.format(val)\n",
    "            for k in range(bit_precision):\n",
    "                file.write(psum_bin[k])\n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = 0 \n",
    "nij = 0 \n",
    "X = o_int[:,nij:nij+64]  # [array row num, time_steps]\n",
    "\n",
    "bit_precision = 16\n",
    "file = open('output_v2.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        val = round(X[7-j,i].item())\n",
    "        if val < 0:\n",
    "                val = val + 2**bit_precision\n",
    "        X_bin = '{0:016b}'.format(val)\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
